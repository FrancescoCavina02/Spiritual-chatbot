# =======================================
# Spiritual AI Guide - Backend Configuration
# =======================================

# -----------------
# Obsidian Vault
# -----------------
OBSIDIAN_VAULT_PATH=/path/to/your/obsidian/vault

# -----------------
# LLM API Keys
# -----------------
# OpenAI (recommended for production)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic Claude (optional)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google Gemini (optional)
GOOGLE_API_KEY=your-google-api-key-here

# -----------------
# LLM Configuration
# -----------------
# Options: openai, ollama, anthropic, gemini
LLM_PROVIDER=openai

# Model names
OPENAI_MODEL=gpt-4-turbo-preview
OLLAMA_MODEL=llama3.1:8b
ANTHROPIC_MODEL=claude-3-sonnet-20240229
GEMINI_MODEL=gemini-pro

# -----------------
# Embedding Model
# -----------------
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# -----------------
# Vector Database
# -----------------
CHROMA_PERSIST_DIRECTORY=./data/embeddings
CHROMA_COLLECTION_NAME=spiritual_notes

# -----------------
# RAG Configuration
# -----------------
# Number of context chunks to retrieve
RAG_TOP_K=5

# Minimum relevance score (0.0 to 1.0)
RAG_MIN_SCORE=0.3

# -----------------
# API Configuration
# -----------------
# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,https://your-frontend-domain.vercel.app

# API rate limiting
RATE_LIMIT_PER_MINUTE=60

# -----------------
# Server Configuration
# -----------------
# Environment: development, production
ENVIRONMENT=production

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

